# main.py (Final Code with Scraping and 422 Fix)

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
import requests
from bs4 import BeautifulSoup
import json
import re
from pydantic import BaseModel # üí° 422 Error Fix: Pydantic BaseModel

# --- 1. Pydantic ‡¶Æ‡¶°‡ßá‡¶≤ (422 ‡¶§‡ßç‡¶∞‡ßÅ‡¶ü‡¶ø ‡¶∏‡¶Æ‡¶æ‡¶ß‡¶æ‡¶®‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø) ---
# ‡¶è‡¶ü‡¶ø ‡¶´‡ßç‡¶∞‡¶®‡ßç‡¶ü‡¶è‡¶®‡ßç‡¶° ‡¶•‡ßá‡¶ï‡ßá ‡¶Ü‡¶∏‡¶æ JSON ‡¶¨‡¶°‡¶ø { "video_url": "..." } ‡¶ï‡ßá ‡¶™‡¶æ‡¶∞‡ßç‡¶∏ ‡¶ï‡¶∞‡¶¨‡ßá‡•§
class VideoRequest(BaseModel):
    video_url: str

# --- 2. FastAPI ‡¶Ö‡ßç‡¶Ø‡¶æ‡¶™‡ßç‡¶≤‡¶ø‡¶ï‡ßá‡¶∂‡¶® ‡¶á‡¶®‡¶∏‡ßç‡¶ü‡ßç‡¶Ø‡¶æ‡¶®‡ßç‡¶∏ ‡¶§‡ßà‡¶∞‡¶ø ---
app = FastAPI(
    title="Video Downloader Backend (Scraping)",
    version="1.0.4",
    description="Backend service using Vidssave scraping to bypass bot detection."
)

# --- 3. CORS Configuration ---
origins = ["*"]
app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- 4. Vidssave.com ‡¶è‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡¶ø‡¶∑‡ßç‡¶ü ‡¶ï‡¶®‡¶´‡¶ø‡¶ó‡¶æ‡¶∞‡ßá‡¶∂‡¶® ---
VIDSSAVE_API_URL = "https://vidssave.com/api/proxy"
VIDSSAVE_HEADERS = {
    # ‡¶¨‡ßç‡¶∞‡¶æ‡¶â‡¶ú‡¶æ‡¶∞ ‡¶π‡¶ø‡¶∏‡ßá‡¶¨‡ßá ‡¶¶‡ßá‡¶ñ‡¶æ‡¶®‡ßã‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶™‡ßç‡¶∞‡¶Ø‡¶º‡ßã‡¶ú‡¶®‡ßÄ‡¶Ø‡¶º Headers
    "Accept": "application/json, text/plain, */*",
    "Content-Type": "application/json",
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Referer": "https://vidssave.com/",
    "Origin": "https://vidssave.com",
    "sec-ch-ua": '"Not.A/Brand";v="99", "Chromium";v="120", "Google Chrome";v="120"',
    "sec-ch-ua-mobile": "?0",
    "sec-ch-ua-platform": '"Windows"',
}


# --- 5. Health Check Endpoint ---
@app.get("/")
def read_root():
    return {"status": "ok", "service": "Backend is running"}


# --- 6. Vidssave Scraping Endpoint (FINAL) ---
@app.post("/scrape/vidssave")
async def scrape_vidssave_info(request: VideoRequest): # üí° Pydantic ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞
    """
    Scrapes download links and info from the Vidssave.com hidden API.
    """
    
    # ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶•‡ßá‡¶ï‡ßá URL ‡¶ü‡¶ø ‡¶¨‡ßá‡¶∞ ‡¶ï‡¶∞‡ßá ‡¶®‡ßá‡¶ì‡¶Ø‡¶º‡¶æ
    video_url = request.video_url

    # POST ‡¶∞‡¶ø‡¶ï‡ßã‡¶Ø‡¶º‡ßá‡¶∏‡ßç‡¶ü‡ßá ‡¶™‡¶æ‡¶†‡¶æ‡¶®‡ßã‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶°‡ßá‡¶ü‡¶æ (Payload)
    payload = {
        "url": video_url,
        "host": "youtube.com"
    }

    try:
        # requests.post() ‡¶∞‡¶ø‡¶ï‡ßã‡¶Ø‡¶º‡ßá‡¶∏‡ßç‡¶ü
        response = requests.post(
            VIDSSAVE_API_URL,
            headers=VIDSSAVE_HEADERS,
            json=payload,
            timeout=15
        )
        response.raise_for_status()

        data = response.json()
        video_data = data.get('data')

        if not video_data or not video_data.get('download_links'):
            error_message = video_data.get('msg') if video_data else "Vidssave failed to process the link."
            raise HTTPException(status_code=400, detail=f"Scraping Failed: {error_message}")

        title = video_data.get('title') or "Untitled Video"
        thumbnail_url = video_data.get('thumbnail')

        extracted_formats = []
        for link in video_data['download_links']:
            quality = link.get('quality') or link.get('type') or "Default"

            # ‡¶∂‡ßÅ‡¶ß‡ßÅ‡¶Æ‡¶æ‡¶§‡ßç‡¶∞ ‡¶™‡ßç‡¶∞‡¶Ø‡¶º‡ßã‡¶ú‡¶®‡ßÄ‡¶Ø‡¶º ‡¶´‡¶∞‡¶Æ‡ßç‡¶Ø‡¶æ‡¶ü‡¶ó‡ßÅ‡¶≤‡ßã ‡¶®‡ßá‡¶ì‡¶Ø‡¶º‡¶æ ‡¶π‡¶ö‡ßç‡¶õ‡ßá
            if link.get('ext') in ('mp4', 'mp3', 'm4a', 'webm'):
                extracted_formats.append({
                    "resolution": quality,
                    "ext": link.get('ext'),
                    "url": link.get('url'),
                    "filesize": link.get('size')
                })

        video_formats = [f for f in extracted_formats if f['ext'] in ('mp4', 'webm')]
        audio_formats = [f for f in extracted_formats if f['ext'] in ('mp3', 'm4a')]

        # Final return structure
        return {
            "title": title,
            "thumbnails": [{"url": thumbnail_url, "resolution": "HQ"}] if thumbnail_url else [],
            "video_formats": video_formats,
            "audio_formats": audio_formats,
            "source": "scraped_vidssave",
        }

    except requests.exceptions.RequestException as e:
        # Network ‡¶¨‡¶æ Connection Error
        raise HTTPException(status_code=503, detail=f"Scraping Failed: Connection error or Vidssave blocked the IP. {str(e)}")
    except Exception as e:
        # ‡¶Ö‡¶®‡ßç‡¶Ø‡¶æ‡¶®‡ßç‡¶Ø ‡¶Ö‡¶®‡¶æ‡¶ï‡¶æ‡¶ô‡ßç‡¶ï‡ßç‡¶∑‡¶ø‡¶§ ‡¶§‡ßç‡¶∞‡ßÅ‡¶ü‡¶ø
        print(f"Scraping Logic Error: {e}")
        raise HTTPException(status_code=500, detail=f"Scraping Logic Error: An internal error occurred.")


# --- ‡¶™‡ßÅ‡¶∞‡¶®‡ßã /yt/info ‡¶è‡¶®‡ßç‡¶°‡¶™‡¶Ø‡¶º‡ßá‡¶®‡ßç‡¶ü ‡¶¨‡¶æ ‡¶Ö‡¶®‡ßç‡¶Ø ‡¶ï‡ßã‡¶®‡ßã ‡¶ï‡ßã‡¶° ‡¶•‡¶æ‡¶ï‡¶≤‡ßá ‡¶è‡¶á ‡¶∏‡ßá‡¶ï‡¶∂‡¶®‡ßá‡¶∞ ‡¶™‡¶∞‡ßá ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡ßÅ‡¶®‡•§ ---
# ...
